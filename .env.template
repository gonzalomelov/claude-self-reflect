# Claude Self-Reflection MCP - Environment Configuration Template
# ==============================================================
# Copy this file to .env and fill in your values

# üîë EMBEDDING PROVIDER CONFIGURATION
# Choose ONE of the following options:

# Option 1: OpenAI (Recommended for general use)
# - Best balance of quality and speed
# - Requires OpenAI API key from https://platform.openai.com/api-keys
# - Cost: ~$0.0001 per 1K tokens
OPENAI_API_KEY=your-openai-api-key-here

# Option 2: Voyage AI (Best for semantic search)
# - Superior search quality for conversation retrieval
# - Get API key from https://dash.voyageai.com/
# - Cost: ~$0.0002 per 1K tokens
VOYAGE_API_KEY=your-voyage-api-key-here

# Option 3: Local Embeddings (Free, lower quality)
# - Uses Sentence Transformers locally
# - No API key required, runs on your machine
# - Set to "true" to enable (overrides API keys above)
USE_LOCAL_EMBEDDINGS=false

# üìÅ CLAUDE DESKTOP CONFIGURATION
# Path to Claude Desktop conversation logs
# Default works for most Mac/Linux installations
CLAUDE_LOGS_PATH=${HOME}/.claude/projects

# üîß QDRANT CONFIGURATION
# Vector database settings (usually no need to change)
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_MEMORY=1g

# ‚öôÔ∏è IMPORT CONFIGURATION
# Batch processing settings for conversation import
BATCH_SIZE=50          # Number of conversations per batch
CHUNK_SIZE=10          # Conversations processed in parallel
WATCH_INTERVAL=60      # Seconds between checking for new conversations

# üß† EMBEDDING MODEL SELECTION
# Choose based on your provider:
# - OpenAI: "text-embedding-3-small" or "text-embedding-3-large"
# - Voyage: "voyage-3" or "voyage-3-lite"
# - Local: "all-MiniLM-L6-v2" or "all-mpnet-base-v2"
EMBEDDING_MODEL=voyage-3

# üîç SEARCH CONFIGURATION
# Similarity threshold for search results (0.0-1.0)
# Lower = more results but less relevant
# Higher = fewer results but more relevant
MIN_SIMILARITY=0.7

# üìä ADVANCED SETTINGS
# Collection naming prefix for multi-user setups
COLLECTION_PREFIX=conv

# Maximum tokens per conversation chunk
MAX_CHUNK_TOKENS=2000

# Enable debug logging
DEBUG=false

# üöÄ PERFORMANCE TUNING
# Number of worker threads for import
WORKERS=4

# Maximum memory for Python processes
PYTHON_MAX_MEMORY=2048

# Connection pool size for Qdrant
QDRANT_POOL_SIZE=10

# üîê SECURITY SETTINGS
# Enable API key encryption at rest
ENCRYPT_API_KEYS=false

# Restrict search to specific projects (comma-separated)
# ALLOWED_PROJECTS=project1,project2

# üìà MONITORING
# Enable performance metrics collection
ENABLE_METRICS=false

# Metrics export endpoint (if enabled)
# METRICS_ENDPOINT=http://localhost:9090/metrics